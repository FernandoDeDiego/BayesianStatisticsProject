index.ea = which.max(data.ea$height[-1]-data.ea$height[-(n-1)])
index.ec = which.max(data.ea$height[-1]-data.ea$height[-(n-1)])
clust.ea2=cutree(data.ea, k = n-index.ea +1)
clust.ec2=cutree(data.ec, k = n-index.ec +1)
return(list(average.Binder = min.a, BI.average = d_absa, complete.Binder = min.c , BI.complete = d_absc, average.PSM=clust.ea,complete.PSM = clust.ec,average.eu = clust.ea2,complete.eu = clust.ec2))
}
#' VI loss
#'
#' Computes expected VI loss and the partition minimizing it
#' @export
VI.loss.draws= function (PYclust, parti=PYclust, print.bar = TRUE) {
if(print.bar) {pb <- txtProgressBar(0, nrow(parti), style = 3)}
VI <- vector(length = nrow(parti))
n = ncol(PYclust)
# sim.mat = array(dim = c(nrow(PYclust),n,n))
# for(i in 1:nrow(PYclust)){sim.mat[i,,]=sapply(PYclust[i,], function(x) x == PYclust[i,])}
# the similarity matrix for any partition visited is put in a big matrix
sim.mat = matrix(ncol = nrow(PYclust)*n, nrow= n)
matrice = matrix(ncol = nrow(PYclust)*n, nrow= n)
for(i in 1:nrow(PYclust)){
sim.mat[,((i-1)*n+1):(i*n)]= sapply(PYclust[i,], function(x) x == PYclust[i,])
}
# VI for each partition
for(i in 1:nrow(parti)){
matrice = sim.mat*as.vector(sapply(parti[i,], function(x) x == parti[i,]))
VI[i] = sum( log2(colSums(sapply(parti[i,], function(x) x == parti[i,])))) - 2/nrow(PYclust) * sum(log2(colSums(matrice)))
if(print.bar) {setTxtProgressBar(pb, i)}
}
if(print.bar) {close(pb)}
return(list(exp.loss = VI,min = parti[which.min(VI),]))
}
#' VI bound using Jensen inequality
#'
#' Computes a bound for expected VI loss and the partition minimizing it
#' @export
VI.ineq.draws = function (PYclust, parti=PYclust, print.bar = TRUE) {
if(print.bar){pb <- txtProgressBar(0, nrow(parti), style = 3)}
VI <- vector(length = nrow(parti))
n = ncol(PYclust)
# Compute PSM
PSM <- matrix( ncol = n, nrow = n)
SM <- matrix( ncol = n, nrow = n)
for(j in 1:n){
for(k in 1:n){
PSM[j,k] <- mean(PYclust[,j] == PYclust[,k])
}
}
for(i in 1:nrow(parti)){
SM = sapply(parti[i,], function(x) x == parti[i,])
VI[i] = sum( log2(colSums(SM))) - 2*sum(log2(colSums(PSM*SM)))
if(print.bar){setTxtProgressBar(pb, i)}
}
if(print.bar){close(pb)}
return(list(exp.loss = VI,min = parti[which.min(VI),]))
}
#' Binder distance for two partitions
#'
#' Binder distance for two partitions
Binder.distance= function (partition1, partition2){
SM1= sapply(partition1, function(x) x == partition1)
SM2= sapply(partition2, function(x) x == partition2)
return(sum(SM1!=SM2))
}
#' VI distance for two partitions
#'
#' VI distance for two partitions
VI.distance= function (partition1, partition2){
N=length(partition1)
mat= matrix(nrow= length(unique(partition1)),ncol = length(unique(partition2)))
for (i in 1:nrow(mat)){
for (j in 1:ncol(mat)){
mat[i,j] = sum((partition1==unique(partition1)[i])*(partition2==unique(partition2)[j]))
}
}
mat= mat/N*log2(mat/N)
sum(table(partition1)/N*log2(table(partition1)/N))+ sum(table(partition2)/N*log2(table(partition2)/N)) - 2 * sum(mat)
}
closest.partitions = function(partition){
m=max(partition)
counts = table(partition)
out = matrix(nrow=0, ncol = length(partition))
if(sum(counts==1)>=2 && sum(counts==2)>=1){
for(i in 1: sum(counts==2)){
cluster = as.numeric(names(counts[counts==2]))[i]
partition2 = partition
partition2[partition2==cluster][2]= m+1
out = rbind(out,partition2,deparse.level = 0)}
comb = combn(sort(as.numeric(names(counts[counts==1]))),2)
for(i in 1:ncol(comb)){
partition2 = partition
partition2[partition2==comb[2,i]]= comb[1,i]
out = rbind(out,partition2,deparse.level = 0)}
}
if(sum(counts==1)>=2 && sum(counts==2)==0){
comb = combn(sort(as.numeric(names(counts[counts==1]))),2)
for(i in 1:ncol(comb)){
partition2 = partition
partition2[partition2==comb[2,i]]= comb[1,i]
out = rbind(out,partition2,deparse.level = 0)}
}
else{
small = min(counts[counts>1])
small.clust = as.numeric(names(counts[counts==small]))
for(i in 1:length(small.clust)){
for(j in 1:small){
partition2 = partition
partition2[partition==small.clust][j]=m+1
out  =rbind(out,partition2,deparse.level = 0)}
}
}
return(out)
}
#' N closest partitions
#'
#' Finds the n closest partitions covering or being covered wrt a given one under B/VI losses
#' @export
n.closest.partition = function(partition, n = 10, distance="VI" ){
if (distance!="Binder"&&distance!="VI"){stop("put a valid distance")}
if (distance == "Binder"){myfun = Binder.distance}
else{myfun= VI.distance}
# partitions covered by mine
m=max(partition)
counts = table(partition)
out = matrix(nrow=0, ncol = length(partition))
counts2 = counts[counts>1]
if(length(counts2)>0){
for(i in 1: length(counts2)){
cluster = as.numeric(names(counts2[i]))
index= which(partition==cluster)
for(j in 1:round(counts2[i]/2)){
comb  = combn(index,j)
for(k in 1:ncol(comb)){
partition2 = partition
partition2[comb[,k]]= m+1
out = rbind(out,partition2,deparse.level = 0)}
}
}
}
#partitions covering mine
if(length(unique(partition) )>1){
comb = combn(unique(partition),2)
for(i in 1:ncol(comb)){
partition2 = partition
partition2[partition==comb[2,i]]= comb[1,i]
out = rbind(out,partition2,deparse.level = 0)}
}
#Calculating selected distance for the partitions found
dis= vector(length=nrow(out))
for(i in nrow(out)){
dis[i]=myfun(partition,out[i])
}
return(out[order(dis)[1:min(n,nrow(out))],])
}
greedy = function (PYclust, partition = PYclust[1,], l= 2*ncol(PYclust), maxiter=1000, distance="VI", Jensen=TRUE) {
if (distance!="Binder"&&distance!="VI"){stop("put a valid distance")}
if (distance=="VI"){loss.draws=VI.loss.draws}
if (Jensen){loss.draws=VI.ineq.draws}
if (distance=="Binder"){loss.draws= B.loss.draws}
pb <- txtProgressBar(0, maxiter, style = 3)
n = ncol(PYclust)
current.loss =  loss.draws(PYclust,t(as.matrix(partition)),FALSE)$exp.loss
previous = partition
current = partition
for (k in 1:maxiter){
my.partitions = n.closest.partition(current,l,distance)
my.list = loss.draws(PYclust,my.partitions,FALSE)
loss= my.list$exp.loss
candidate= my.list$min
if(min(loss)>current.loss){break}
if(sum(sapply(candidate, function(x) x == candidate)-
sapply(previous, function(x) x == previous))==0){
print("we re stuck in two partitions with same loss")
break
}
previous = current
current = candidate
current.loss = min(loss)
setTxtProgressBar(pb, k)
}
close(pb)
print(paste("iterazione numero ",k))
return(list(cluster = current, exp.loss = current.loss))
}
library(coda)
library(BNPmix)
library(ggplot2)
library(tidyr)
library(dplyr)
library(purrr)
library(ggsci)
library(MYpackage)
library(dplyr)
#' Expected number of cluster
#'
#' Uses theoretical result of the DP
#' @export
ENOC <- function(alpha, n){
sum(alpha / (alpha + 0:(n - 1)))
}
#' Reordering a dataframe of partitions
#'
#' Reorders output clusters in such a way that the cluster number is increasing by 1 starting from 1 in order of appearance
#' @export
cluster.reorder = function(clust.matrix) {
clust.out = matrix(nrow=nrow(clust.matrix), ncol=ncol(clust.matrix))
for (i in 1:nrow(clust.matrix)) {
a= unique(clust.matrix[i,])
for (j in 1:length(a)){
clust.out[i,clust.matrix[i,]==a[j]] = j
}
}
return (clust.out)
}
#'Partition Counter
#'
#'Counting the partitions visited by an MCMC - or computing the mode if you want
#' @export
partitions.counter = function(clust.unordered){
clust.ordered = cluster.reorder(clust.unordered)
return(as.matrix(arrange(summarize(group_by_all(as.data.frame(clust.ordered)),number=n()),desc(number))))
}
#' BINDER LOSS Function
#'
#' Computes Binder loss for each partition and the minimizer
#' @export
B.loss.draws= function ( PYclust, parti=PYclust, useless_param= TRUE) {
n= ncol(PYclust)
# compute the posterior similarity matrix
PSM <- matrix(0, ncol = n, nrow = n)
for(j in 1:n){
for(k in 1:n){
PSM[j,k] <- mean(PYclust[,j] == PYclust[,k])
}
}
# Compute the distance for each partition to the PSM and
# get the optimal one
d_abs <- c()
for(i in 1:nrow(parti)){
d_abs[i] <- sum(abs(1 * (sapply(parti[i,],
function(x) x == parti[i,])) - PSM))
}
return(list(exp.loss = d_abs,min = parti[which.min(d_abs),]))
}
#' Hierarchical clustering of the data
#'
#' Various hierarchical clustering based on PSM and distance-based
#' @export
Hier= function (PYdens) {
# Compute dissimilarity matrix 1-PSM
n = ncol(PYdens$clust)
PSM <- matrix(0, ncol = n, nrow = n)
for(j in 1:n){
for(k in 1:n){
PSM[j,k] <- mean(PYdens$clust[,j] == PYdens$clust[,k])
}
}
PDM = 1-PSM
# H. Clustering and compute binder Loss for
# clusters explored by the method (average, complete)
data.ea <- hclust(as.dist(PDM), method='average')
data.ec <- hclust(as.dist(PDM), method='complete')
part.ea = t(cutree(data.ea, k = 1:n))
part.ec = t(cutree(data.ec, k = 1:n))
d_absa <- c()
for(i in 1:nrow(part.ea)){
d_absa[i] <- sum(abs(1 * (sapply(part.ea[i,],
function(x) x == part.ea[i,])) - PSM))
}
min.a = part.ea[which.min(d_absa),]
d_absc = c()
for(i in 1:nrow(part.ec)){
d_absc[i] <- sum(abs(1 * (sapply(part.ec[i,],
function(x) x == part.ec[i,])) - PSM))
}
min.c = part.ec[which.min(d_absc),]
# Partition estimate based on hierarchical clustering
# for the PDM and for euclidean distance
index.ea = which.max(data.ea$height[-1]-data.ea$height[-(n-1)])
index.ec = which.max(data.ea$height[-1]-data.ea$height[-(n-1)])
clust.ea =cutree(data.ea, k = n-index.ea +1)
clust.ec =cutree(data.ec, k = n-index.ec +1)
DM = dist(PYdens$data)
data.ea <- hclust(DM, method='average')
data.ec <- hclust(DM, method='complete')
index.ea = which.max(data.ea$height[-1]-data.ea$height[-(n-1)])
index.ec = which.max(data.ea$height[-1]-data.ea$height[-(n-1)])
clust.ea2=cutree(data.ea, k = n-index.ea +1)
clust.ec2=cutree(data.ec, k = n-index.ec +1)
return(list(average.Binder = min.a, BI.average = d_absa, complete.Binder = min.c , BI.complete = d_absc, average.PSM=clust.ea,complete.PSM = clust.ec,average.eu = clust.ea2,complete.eu = clust.ec2))
}
#' VI loss
#'
#' Computes expected VI loss and the partition minimizing it
#' @export
VI.loss.draws= function (PYclust, parti=PYclust, print.bar = TRUE) {
if(print.bar) {pb <- txtProgressBar(0, nrow(parti), style = 3)}
VI <- vector(length = nrow(parti))
n = ncol(PYclust)
# sim.mat = array(dim = c(nrow(PYclust),n,n))
# for(i in 1:nrow(PYclust)){sim.mat[i,,]=sapply(PYclust[i,], function(x) x == PYclust[i,])}
# the similarity matrix for any partition visited is put in a big matrix
sim.mat = matrix(ncol = nrow(PYclust)*n, nrow= n)
matrice = matrix(ncol = nrow(PYclust)*n, nrow= n)
for(i in 1:nrow(PYclust)){
sim.mat[,((i-1)*n+1):(i*n)]= sapply(PYclust[i,], function(x) x == PYclust[i,])
}
# VI for each partition
for(i in 1:nrow(parti)){
matrice = sim.mat*as.vector(sapply(parti[i,], function(x) x == parti[i,]))
VI[i] = sum( log2(colSums(sapply(parti[i,], function(x) x == parti[i,])))) - 2/nrow(PYclust) * sum(log2(colSums(matrice)))
if(print.bar) {setTxtProgressBar(pb, i)}
}
if(print.bar) {close(pb)}
return(list(exp.loss = VI,min = parti[which.min(VI),]))
}
#' VI bound using Jensen inequality
#'
#' Computes a bound for expected VI loss and the partition minimizing it
#' @export
VI.ineq.draws = function (PYclust, parti=PYclust, print.bar = TRUE) {
if(print.bar){pb <- txtProgressBar(0, nrow(parti), style = 3)}
VI <- vector(length = nrow(parti))
n = ncol(PYclust)
# Compute PSM
PSM <- matrix( ncol = n, nrow = n)
SM <- matrix( ncol = n, nrow = n)
for(j in 1:n){
for(k in 1:n){
PSM[j,k] <- mean(PYclust[,j] == PYclust[,k])
}
}
for(i in 1:nrow(parti)){
SM = sapply(parti[i,], function(x) x == parti[i,])
VI[i] = sum( log2(colSums(SM))) - 2*sum(log2(colSums(PSM*SM)))
if(print.bar){setTxtProgressBar(pb, i)}
}
if(print.bar){close(pb)}
return(list(exp.loss = VI,min = parti[which.min(VI),]))
}
#' Binder distance for two partitions
#'
#' Binder distance for two partitions
Binder.distance= function (partition1, partition2){
SM1= sapply(partition1, function(x) x == partition1)
SM2= sapply(partition2, function(x) x == partition2)
return(sum(SM1!=SM2))
}
#' VI distance for two partitions
#'
#' VI distance for two partitions
VI.distance= function (partition1, partition2){
N=length(partition1)
mat= matrix(nrow= length(unique(partition1)),ncol = length(unique(partition2)))
for (i in 1:nrow(mat)){
for (j in 1:ncol(mat)){
mat[i,j] = sum((partition1==unique(partition1)[i])*(partition2==unique(partition2)[j]))
}
}
mat= mat/N*log2(mat/N)
sum(table(partition1)/N*log2(table(partition1)/N))+ sum(table(partition2)/N*log2(table(partition2)/N)) - 2 * sum(mat)
}
closest.partitions = function(partition){
m=max(partition)
counts = table(partition)
out = matrix(nrow=0, ncol = length(partition))
if(sum(counts==1)>=2 && sum(counts==2)>=1){
for(i in 1: sum(counts==2)){
cluster = as.numeric(names(counts[counts==2]))[i]
partition2 = partition
partition2[partition2==cluster][2]= m+1
out = rbind(out,partition2,deparse.level = 0)}
comb = combn(sort(as.numeric(names(counts[counts==1]))),2)
for(i in 1:ncol(comb)){
partition2 = partition
partition2[partition2==comb[2,i]]= comb[1,i]
out = rbind(out,partition2,deparse.level = 0)}
}
if(sum(counts==1)>=2 && sum(counts==2)==0){
comb = combn(sort(as.numeric(names(counts[counts==1]))),2)
for(i in 1:ncol(comb)){
partition2 = partition
partition2[partition2==comb[2,i]]= comb[1,i]
out = rbind(out,partition2,deparse.level = 0)}
}
else{
small = min(counts[counts>1])
small.clust = as.numeric(names(counts[counts==small]))
for(i in 1:length(small.clust)){
for(j in 1:small){
partition2 = partition
partition2[partition==small.clust][j]=m+1
out  =rbind(out,partition2,deparse.level = 0)}
}
}
return(out)
}
#' N closest partitions
#'
#' Finds the n closest partitions covering or being covered wrt a given one under B/VI losses
#' @export
n.closest.partition = function(partition, n = 10, distance="VI" ){
if (distance!="Binder"&&distance!="VI"){stop("put a valid distance")}
if (distance == "Binder"){myfun = Binder.distance}
else{myfun= VI.distance}
# partitions covered by mine
m=max(partition)
counts = table(partition)
out = matrix(nrow=0, ncol = length(partition))
counts2 = counts[counts>1]
if(length(counts2)>0){
for(i in 1: length(counts2)){
cluster = as.numeric(names(counts2[i]))
index= which(partition==cluster)
for(j in 1:round(counts2[i]/2)){
comb  = combn(index,j)
for(k in 1:ncol(comb)){
partition2 = partition
partition2[comb[,k]]= m+1
out = rbind(out,partition2,deparse.level = 0)}
}
}
}
#partitions covering mine
if(length(unique(partition) )>1){
comb = combn(unique(partition),2)
for(i in 1:ncol(comb)){
partition2 = partition
partition2[partition==comb[2,i]]= comb[1,i]
out = rbind(out,partition2,deparse.level = 0)}
}
#Calculating selected distance for the partitions found
dis= vector(length=nrow(out))
for(i in nrow(out)){
dis[i]=myfun(partition,out[i])
}
return(out[order(dis)[1:min(n,nrow(out))],])
}
greedy = function (PYclust, partition = PYclust[1,], l= 2*ncol(PYclust), maxiter=1000, distance="VI", Jensen=TRUE) {
if (distance!="Binder"&&distance!="VI"){stop("put a valid distance")}
if (distance=="VI"){loss.draws=VI.loss.draws}
if (Jensen){loss.draws=VI.ineq.draws}
if (distance=="Binder"){loss.draws= B.loss.draws}
pb <- txtProgressBar(0, maxiter, style = 3)
n = ncol(PYclust)
current.loss =  loss.draws(PYclust,t(as.matrix(partition)),FALSE)$exp.loss
previous = partition
current = partition
for (k in 1:maxiter){
my.partitions = n.closest.partition(current,l,distance)
my.list = loss.draws(PYclust,my.partitions,FALSE)
loss= my.list$exp.loss
candidate= my.list$min
if(min(loss)>current.loss){break}
if(sum(sapply(candidate, function(x) x == candidate)-
sapply(previous, function(x) x == previous))==0){
print("we re stuck in two partitions with same loss")
break
}
previous = current
current = candidate
current.loss = min(loss)
setTxtProgressBar(pb, k)
}
close(pb)
print(paste("iterazione numero ",k))
return(list(cluster = current, exp.loss = current.loss))
}
View(ENOC)
library(coda)
library(BNPmix)
library(ggplot2)
library(tidyr)
library(dplyr)
library(purrr)
library(ggsci)
library(MYpackage)
install.packages("C:/Users/Fernando/Desktop/Bayesian Statistics/BayesianStatisticsProject/MYpackage/R/functions.R", repos = NULL)
library(coda)
library(BNPmix)
library(ggplot2)
library(tidyr)
library(dplyr)
library(purrr)
library(ggsci)
install.packages('MYpackage')
library(MYpackage)
library(coda)
library(BNPmix)
library(ggplot2)
library(tidyr)
library(dplyr)
library(purrr)
library(ggsci)
install.packages('C:\Users\Fernando\Desktop\Bayesian Statistics\BayesianStatisticsProject\MYpackage')
install.packages('\Users\Fernando\Desktop\Bayesian Statistics\BayesianStatisticsProject\MYpackage')
library(coda)
library(BNPmix)
library(ggplot2)
library(tidyr)
library(dplyr)
library(purrr)
library(ggsci)
setwd('C:\Users\Fernando\Desktop\Bayesian Statistics\BayesianStatisticsProject')
install.packages('MYpackage')
library(MYpackage)
setwd('\Users\Fernando\Desktop\Bayesian Statistics\BayesianStatisticsProject')
install.packages('MYpackage')
install.packages('installr')
library(installr)
updateR()
updateR()
updateR()
